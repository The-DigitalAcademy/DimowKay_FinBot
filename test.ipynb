{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Would I ever need credit card if my debit card...</td>\n",
       "      <td>Skimmers are most likely at gas station pumps....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheapest way to wire or withdraw money from US...</td>\n",
       "      <td>There is a number of cheaper online options th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I go about finding an honest  ethical f...</td>\n",
       "      <td>Large and wellknown companies are typically a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why invest in becoming a landlord?</td>\n",
       "      <td>why does it make sense financially to buy prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What could be the cause of a extreme highlow p...</td>\n",
       "      <td>Often these types of trades fall into two diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12042</th>\n",
       "      <td>What percent of my salary should I save?</td>\n",
       "      <td>I disagree with the selected answer. Theres no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12043</th>\n",
       "      <td>Why do people invest in mutual fund rather tha...</td>\n",
       "      <td>How on earth can you possibly know what is goi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12044</th>\n",
       "      <td>What would happen if the Euro currency went bust?</td>\n",
       "      <td>Each country would have to go back to its own ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12045</th>\n",
       "      <td>Are credit cards not viewed as credit until yo...</td>\n",
       "      <td>Theres a difference between missing a payment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12046</th>\n",
       "      <td>Does the stock market create any sort of value?</td>\n",
       "      <td>When you own stock in a company, you do litera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12047 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      Would I ever need credit card if my debit card...   \n",
       "1      Cheapest way to wire or withdraw money from US...   \n",
       "2      How do I go about finding an honest  ethical f...   \n",
       "3                     Why invest in becoming a landlord?   \n",
       "4      What could be the cause of a extreme highlow p...   \n",
       "...                                                  ...   \n",
       "12042           What percent of my salary should I save?   \n",
       "12043  Why do people invest in mutual fund rather tha...   \n",
       "12044  What would happen if the Euro currency went bust?   \n",
       "12045  Are credit cards not viewed as credit until yo...   \n",
       "12046    Does the stock market create any sort of value?   \n",
       "\n",
       "                                                  answer  \n",
       "0      Skimmers are most likely at gas station pumps....  \n",
       "1      There is a number of cheaper online options th...  \n",
       "2      Large and wellknown companies are typically a ...  \n",
       "3      why does it make sense financially to buy prop...  \n",
       "4      Often these types of trades fall into two diff...  \n",
       "...                                                  ...  \n",
       "12042  I disagree with the selected answer. Theres no...  \n",
       "12043  How on earth can you possibly know what is goi...  \n",
       "12044  Each country would have to go back to its own ...  \n",
       "12045  Theres a difference between missing a payment ...  \n",
       "12046  When you own stock in a company, you do litera...  \n",
       "\n",
       "[12047 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "clean the text by removing extra spaces, special characters, and unwanted symbols.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I defined a function called data cleaning.\n",
    "The function will do the following:\n",
    "1. remove punctuations but keep things like currency, numbers, and percentages. Please keep in mind that the finBOT may make use of these hence we're keeping them.\n",
    "\n",
    "2. The function will convert all text to lower case and get rid of whitespaces from the start and the end of the string for consistency.\n",
    "\n",
    "\n",
    "Example: \" Tokenization sucks \" => \"tokenization sucks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "    text = re.sub(r'[^\\w\\s.$%€£0-9]', '', text)\n",
    "    text =  text.lower().strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['question'].apply(data_cleaning)\n",
    "df['answer'] = df['answer'].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "1. Word level tokenization\n",
    "2. Lemmatization\n",
    "3. Subword Tokenization\n",
    "4. Sentence Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Word level Tokenization\n",
    "\n",
    "Here we are just splitting text into individual words.\n",
    "\n",
    "Example: \"interest rate increases\" => [\"interest\", \"rate\", \"increases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/tshmacm1172/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  would i ever need credit card if my debit card...   \n",
      "1  cheapest way to wire or withdraw money from us...   \n",
      "2  how do i go about finding an honest  ethical f...   \n",
      "3                  why invest in becoming a landlord   \n",
      "4  what could be the cause of a extreme highlow p...   \n",
      "\n",
      "                                 word_token_question  \n",
      "0  [would, i, ever, need, credit, card, if, my, d...  \n",
      "1  [cheapest, way, to, wire, or, withdraw, money,...  \n",
      "2  [how, do, i, go, about, finding, an, honest, e...  \n",
      "3           [why, invest, in, becoming, a, landlord]  \n",
      "4  [what, could, be, the, cause, of, a, extreme, ...  \n",
      "                                              answer  \\\n",
      "0  skimmers are most likely at gas station pumps....   \n",
      "1  there is a number of cheaper online options th...   \n",
      "2  large and wellknown companies are typically a ...   \n",
      "3  why does it make sense financially to buy prop...   \n",
      "4  often these types of trades fall into two diff...   \n",
      "\n",
      "                                   word_token_answer  \n",
      "0  [skimmers, are, most, likely, at, gas, station...  \n",
      "1  [there, is, a, number, of, cheaper, online, op...  \n",
      "2  [large, and, wellknown, companies, are, typica...  \n",
      "3  [why, does, it, make, sense, financially, to, ...  \n",
      "4  [often, these, types, of, trades, fall, into, ...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "df[\"word_token_question\"] = df[\"question\"].apply(word_tokenize)\n",
    "df[\"word_token_answer\"] = df[\"answer\"].apply(word_tokenize)\n",
    "\n",
    "print(df[[\"question\", \"word_token_question\"]].head())\n",
    "print(df[[\"answer\", \"word_token_answer\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lemmatization\n",
    "takes words to their root word\n",
    "\n",
    "Example: \"Motsekuwa\" => \"Mo\"\n",
    "\n",
    "Note: run this line of code first: pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m950.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "                                            question  \\\n",
      "0  would i ever need credit card if my debit card...   \n",
      "1  cheapest way to wire or withdraw money from us...   \n",
      "2  how do i go about finding an honest  ethical f...   \n",
      "3                  why invest in becoming a landlord   \n",
      "4  what could be the cause of a extreme highlow p...   \n",
      "\n",
      "                           lemmatized_token_question  \n",
      "0  [would, I, ever, need, credit, card, if, my, d...  \n",
      "1  [cheap, way, to, wire, or, withdraw, money, fr...  \n",
      "2  [how, do, I, go, about, find, an, honest,  , e...  \n",
      "3             [why, invest, in, become, a, landlord]  \n",
      "4  [what, could, be, the, cause, of, a, extreme, ...  \n",
      "                                              answer  \\\n",
      "0  skimmers are most likely at gas station pumps....   \n",
      "1  there is a number of cheaper online options th...   \n",
      "2  large and wellknown companies are typically a ...   \n",
      "3  why does it make sense financially to buy prop...   \n",
      "4  often these types of trades fall into two diff...   \n",
      "\n",
      "                             lemmatized_token_answer  \n",
      "0  [skimmer, be, most, likely, at, gas, station, ...  \n",
      "1  [there, be, a, number, of, cheap, online, opti...  \n",
      "2  [large, and, wellknown, company, be, typically...  \n",
      "3  [why, do, it, make, sense, financially, to, bu...  \n",
      "4  [often, these, type, of, trade, fall, into, tw...  \n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "df[\"lemmatized_token_question\"] = df[\"question\"].apply(lemmatize_text)\n",
    "df[\"lemmatized_token_answer\"] = df[\"answer\"].apply(lemmatize_text)\n",
    "print(df[[\"question\", \"lemmatized_token_question\"]].head())\n",
    "print(df[[\"answer\", \"lemmatized_token_answer\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Subword Tokenization\n",
    "it makes sure that complicated words and non \"dictionarized\" words are processed efficiently\n",
    "\n",
    "Example: finbotization => \"finbot\", \"ization\"\n",
    "\n",
    "Note: run this line of code first: pip install transformers. \n",
    "\n",
    "### \"Ġ\" appears before words that originally had a space before them to ensure correct spacing when reconstructing the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.auto.tokenization_auto because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nmodule 'numpy._core' has no attribute 'multiarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/generation/utils.py:120\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlignDevicesHook, add_hook_to_module\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Variable names used to hold the cache at generation time\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/__init__.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.6.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     cpu_offload,\n\u001b[1;32m     19\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/accelerator.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_torch_state_dict_into_shards\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_torchao_available\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/utils/__init__.py:218\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    208\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m    209\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m         map_pytorch_optim_to_deepspeed,\n\u001b[1;32m    216\u001b[0m     )\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbnb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    220\u001b[0m     disable_fsdp_ram_efficient_loading,\n\u001b[1;32m    221\u001b[0m     enable_fsdp_ram_efficient_loading,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m     save_fsdp_optimizer,\n\u001b[1;32m    232\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/utils/bnb.py:29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimports\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     is_4bit_bnb_available,\n\u001b[1;32m     26\u001b[0m     is_8bit_bnb_available,\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch_model, init_empty_weights\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BnbQuantizationConfig\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/big_modeling.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     AlignDevicesHook,\n\u001b[1;32m     26\u001b[0m     CpuOffload,\n\u001b[1;32m     27\u001b[0m     UserCpuOffloadHook,\n\u001b[1;32m     28\u001b[0m     add_hook_to_module,\n\u001b[1;32m     29\u001b[0m     attach_align_device_hook,\n\u001b[1;32m     30\u001b[0m     attach_align_device_hook_on_blocks,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     OffloadedWeightsLoader,\n\u001b[1;32m     34\u001b[0m     check_cuda_p2p_ib_support,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     retie_parameters,\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/hooks.py:37\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_non_persistent_buffers\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m recursive_getattr\n\u001b[1;32m     40\u001b[0m _accelerate_added_attributes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdaa\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmusa\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/utils/other.py:225\u001b[0m\n\u001b[1;32m    222\u001b[0m np_core \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m_core \u001b[38;5;28;01mif\u001b[39;00m is_numpy_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcore\n\u001b[1;32m    223\u001b[0m TORCH_SAFE_GLOBALS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# numpy arrays are just numbers, not objects, so we can reconstruct them safely\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     np_core\u001b[38;5;241m.\u001b[39mmultiarray\u001b[38;5;241m.\u001b[39m_reconstruct,\n\u001b[1;32m    226\u001b[0m     np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# The following are needed for the RNG states\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     encode,\n\u001b[1;32m    229\u001b[0m     np\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    230\u001b[0m ]\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_numpy_available(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy._core' has no attribute 'multiarray'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoder_decoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncoderDecoderConfig\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto_factory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LazyAutoMapping\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     40\u001b[0m     CONFIG_MAPPING_NAMES,\n\u001b[1;32m     41\u001b[0m     AutoConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     replace_list_option_in_docstrings,\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:40\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[1;32m     43\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\nmodule 'numpy._core' has no attribute 'multiarray'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubword_token_question\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: tokenizer\u001b[38;5;241m.\u001b[39mtokenize(x))\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1956\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m-> 1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m   1958\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.auto.tokenization_auto because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nmodule 'numpy._core' has no attribute 'multiarray'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "df[\"subword_token_question\"] = df[\"question\"].apply(lambda x: tokenizer.tokenize(x))\n",
    "df[\"subword_token_answer\"] = df[\"answer\"].apply(lambda x: tokenizer.tokenize(x))\n",
    "print(df[[\"question\", \"subword_token_question\"]].head())\n",
    "print(df[[\"answer\", \"subword_token_answer\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sentence Tokenization\n",
    "\n",
    "this will ensure we still keep the sentence\n",
    "Example: Interest rates will rise. Investors are adjusting portfolios. => [\"Interest rates will rise.\", \"Investors are adjusting portfolios.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  would i ever need credit card if my debit card...   \n",
      "1  cheapest way to wire or withdraw money from us...   \n",
      "2  how do i go about finding an honest  ethical f...   \n",
      "3                  why invest in becoming a landlord   \n",
      "4  what could be the cause of a extreme highlow p...   \n",
      "\n",
      "                        sentence_tokenized_questions  \n",
      "0  [would i ever need credit card if my debit car...  \n",
      "1  [cheapest way to wire or withdraw money from u...  \n",
      "2  [how do i go about finding an honest  ethical ...  \n",
      "3                [why invest in becoming a landlord]  \n",
      "4  [what could be the cause of a extreme highlow ...  \n",
      "                                              answer  \\\n",
      "0  skimmers are most likely at gas station pumps....   \n",
      "1  there is a number of cheaper online options th...   \n",
      "2  large and wellknown companies are typically a ...   \n",
      "3  why does it make sense financially to buy prop...   \n",
      "4  often these types of trades fall into two diff...   \n",
      "\n",
      "                          sentence_tokenized_answers  \n",
      "0  [skimmers are most likely at gas station pumps...  \n",
      "1  [there is a number of cheaper online options t...  \n",
      "2  [large and wellknown companies are typically a...  \n",
      "3  [why does it make sense financially to buy pro...  \n",
      "4  [often these types of trades fall into two dif...  \n"
     ]
    }
   ],
   "source": [
    "def sentence_tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [sent.text for sent in doc.sents]  \n",
    "\n",
    "df[\"sentence_tokenized_questions\"] = df[\"question\"].apply(sentence_tokenize)\n",
    "df[\"sentence_tokenized_answers\"] = df[\"answer\"].apply(sentence_tokenize)\n",
    "\n",
    "\n",
    "print(df[[\"question\", \"sentence_tokenized_questions\"]].head())\n",
    "print(df[[\"answer\", \"sentence_tokenized_answers\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>word_token_question</th>\n",
       "      <th>word_token_answer</th>\n",
       "      <th>lemmatized_token_question</th>\n",
       "      <th>lemmatized_token_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>would i ever need credit card if my debit card...</td>\n",
       "      <td>skimmers are most likely at gas station pumps....</td>\n",
       "      <td>[would, i, ever, need, credit, card, if, my, d...</td>\n",
       "      <td>[skimmers, are, most, likely, at, gas, station...</td>\n",
       "      <td>[would, I, ever, need, credit, card, if, my, d...</td>\n",
       "      <td>[skimmer, be, most, likely, at, gas, station, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cheapest way to wire or withdraw money from us...</td>\n",
       "      <td>there is a number of cheaper online options th...</td>\n",
       "      <td>[cheapest, way, to, wire, or, withdraw, money,...</td>\n",
       "      <td>[there, is, a, number, of, cheaper, online, op...</td>\n",
       "      <td>[cheap, way, to, wire, or, withdraw, money, fr...</td>\n",
       "      <td>[there, be, a, number, of, cheap, online, opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do i go about finding an honest  ethical f...</td>\n",
       "      <td>large and wellknown companies are typically a ...</td>\n",
       "      <td>[how, do, i, go, about, finding, an, honest, e...</td>\n",
       "      <td>[large, and, wellknown, companies, are, typica...</td>\n",
       "      <td>[how, do, I, go, about, find, an, honest,  , e...</td>\n",
       "      <td>[large, and, wellknown, company, be, typically...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why invest in becoming a landlord</td>\n",
       "      <td>why does it make sense financially to buy prop...</td>\n",
       "      <td>[why, invest, in, becoming, a, landlord]</td>\n",
       "      <td>[why, does, it, make, sense, financially, to, ...</td>\n",
       "      <td>[why, invest, in, become, a, landlord]</td>\n",
       "      <td>[why, do, it, make, sense, financially, to, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what could be the cause of a extreme highlow p...</td>\n",
       "      <td>often these types of trades fall into two diff...</td>\n",
       "      <td>[what, could, be, the, cause, of, a, extreme, ...</td>\n",
       "      <td>[often, these, types, of, trades, fall, into, ...</td>\n",
       "      <td>[what, could, be, the, cause, of, a, extreme, ...</td>\n",
       "      <td>[often, these, type, of, trade, fall, into, tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12042</th>\n",
       "      <td>what percent of my salary should i save</td>\n",
       "      <td>i disagree with the selected answer. theres no...</td>\n",
       "      <td>[what, percent, of, my, salary, should, i, save]</td>\n",
       "      <td>[i, disagree, with, the, selected, answer, ., ...</td>\n",
       "      <td>[what, percent, of, my, salary, should, I, save]</td>\n",
       "      <td>[I, disagree, with, the, select, answer, ., th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12043</th>\n",
       "      <td>why do people invest in mutual fund rather tha...</td>\n",
       "      <td>how on earth can you possibly know what is goi...</td>\n",
       "      <td>[why, do, people, invest, in, mutual, fund, ra...</td>\n",
       "      <td>[how, on, earth, can, you, possibly, know, wha...</td>\n",
       "      <td>[why, do, people, invest, in, mutual, fund, ra...</td>\n",
       "      <td>[how, on, earth, can, you, possibly, know, wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12044</th>\n",
       "      <td>what would happen if the euro currency went bust</td>\n",
       "      <td>each country would have to go back to its own ...</td>\n",
       "      <td>[what, would, happen, if, the, euro, currency,...</td>\n",
       "      <td>[each, country, would, have, to, go, back, to,...</td>\n",
       "      <td>[what, would, happen, if, the, euro, currency,...</td>\n",
       "      <td>[each, country, would, have, to, go, back, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12045</th>\n",
       "      <td>are credit cards not viewed as credit until yo...</td>\n",
       "      <td>theres a difference between missing a payment ...</td>\n",
       "      <td>[are, credit, cards, not, viewed, as, credit, ...</td>\n",
       "      <td>[theres, a, difference, between, missing, a, p...</td>\n",
       "      <td>[be, credit, card, not, view, as, credit, unti...</td>\n",
       "      <td>[there, s, a, difference, between, miss, a, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12046</th>\n",
       "      <td>does the stock market create any sort of value</td>\n",
       "      <td>when you own stock in a company you do literal...</td>\n",
       "      <td>[does, the, stock, market, create, any, sort, ...</td>\n",
       "      <td>[when, you, own, stock, in, a, company, you, d...</td>\n",
       "      <td>[do, the, stock, market, create, any, sort, of...</td>\n",
       "      <td>[when, you, own, stock, in, a, company, you, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12047 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0      would i ever need credit card if my debit card...   \n",
       "1      cheapest way to wire or withdraw money from us...   \n",
       "2      how do i go about finding an honest  ethical f...   \n",
       "3                      why invest in becoming a landlord   \n",
       "4      what could be the cause of a extreme highlow p...   \n",
       "...                                                  ...   \n",
       "12042            what percent of my salary should i save   \n",
       "12043  why do people invest in mutual fund rather tha...   \n",
       "12044   what would happen if the euro currency went bust   \n",
       "12045  are credit cards not viewed as credit until yo...   \n",
       "12046     does the stock market create any sort of value   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      skimmers are most likely at gas station pumps....   \n",
       "1      there is a number of cheaper online options th...   \n",
       "2      large and wellknown companies are typically a ...   \n",
       "3      why does it make sense financially to buy prop...   \n",
       "4      often these types of trades fall into two diff...   \n",
       "...                                                  ...   \n",
       "12042  i disagree with the selected answer. theres no...   \n",
       "12043  how on earth can you possibly know what is goi...   \n",
       "12044  each country would have to go back to its own ...   \n",
       "12045  theres a difference between missing a payment ...   \n",
       "12046  when you own stock in a company you do literal...   \n",
       "\n",
       "                                     word_token_question  \\\n",
       "0      [would, i, ever, need, credit, card, if, my, d...   \n",
       "1      [cheapest, way, to, wire, or, withdraw, money,...   \n",
       "2      [how, do, i, go, about, finding, an, honest, e...   \n",
       "3               [why, invest, in, becoming, a, landlord]   \n",
       "4      [what, could, be, the, cause, of, a, extreme, ...   \n",
       "...                                                  ...   \n",
       "12042   [what, percent, of, my, salary, should, i, save]   \n",
       "12043  [why, do, people, invest, in, mutual, fund, ra...   \n",
       "12044  [what, would, happen, if, the, euro, currency,...   \n",
       "12045  [are, credit, cards, not, viewed, as, credit, ...   \n",
       "12046  [does, the, stock, market, create, any, sort, ...   \n",
       "\n",
       "                                       word_token_answer  \\\n",
       "0      [skimmers, are, most, likely, at, gas, station...   \n",
       "1      [there, is, a, number, of, cheaper, online, op...   \n",
       "2      [large, and, wellknown, companies, are, typica...   \n",
       "3      [why, does, it, make, sense, financially, to, ...   \n",
       "4      [often, these, types, of, trades, fall, into, ...   \n",
       "...                                                  ...   \n",
       "12042  [i, disagree, with, the, selected, answer, ., ...   \n",
       "12043  [how, on, earth, can, you, possibly, know, wha...   \n",
       "12044  [each, country, would, have, to, go, back, to,...   \n",
       "12045  [theres, a, difference, between, missing, a, p...   \n",
       "12046  [when, you, own, stock, in, a, company, you, d...   \n",
       "\n",
       "                               lemmatized_token_question  \\\n",
       "0      [would, I, ever, need, credit, card, if, my, d...   \n",
       "1      [cheap, way, to, wire, or, withdraw, money, fr...   \n",
       "2      [how, do, I, go, about, find, an, honest,  , e...   \n",
       "3                 [why, invest, in, become, a, landlord]   \n",
       "4      [what, could, be, the, cause, of, a, extreme, ...   \n",
       "...                                                  ...   \n",
       "12042   [what, percent, of, my, salary, should, I, save]   \n",
       "12043  [why, do, people, invest, in, mutual, fund, ra...   \n",
       "12044  [what, would, happen, if, the, euro, currency,...   \n",
       "12045  [be, credit, card, not, view, as, credit, unti...   \n",
       "12046  [do, the, stock, market, create, any, sort, of...   \n",
       "\n",
       "                                 lemmatized_token_answer  \n",
       "0      [skimmer, be, most, likely, at, gas, station, ...  \n",
       "1      [there, be, a, number, of, cheap, online, opti...  \n",
       "2      [large, and, wellknown, company, be, typically...  \n",
       "3      [why, do, it, make, sense, financially, to, bu...  \n",
       "4      [often, these, type, of, trade, fall, into, tw...  \n",
       "...                                                  ...  \n",
       "12042  [I, disagree, with, the, select, answer, ., th...  \n",
       "12043  [how, on, earth, can, you, possibly, know, wha...  \n",
       "12044  [each, country, would, have, to, go, back, to,...  \n",
       "12045  [there, s, a, difference, between, miss, a, pa...  \n",
       "12046  [when, you, own, stock, in, a, company, you, d...  \n",
       "\n",
       "[12047 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary and Vectorization\n",
    "- **Vocabulary**: A vocabulary is a mapping of unique words (tokens) to numerical indices, allowing text to be represented as numbers for machine learning models. It’s essential for transforming words into a format that models can process.\n",
    "\n",
    "- **Vectorization**: Vectorization is the process of converting text into numerical representations (vectors). This is done using the vocabulary, where each word is replaced by its corresponding index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "1. Sentence: ['what', 'be', 'interest', 'rate']\n",
    "\n",
    "2. Vocabulary: {'<'PAD'>': 0, <'UNK'>: 1, 'what': 2, 'be': 3, 'interest': 4, 'rate': 5}\n",
    "\n",
    "3. Vector: [2, 3, 4, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'answer', 'word_token_question', 'word_token_answer',\n",
       "       'lemmatized_token_question', 'lemmatized_token_answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "vocab = defaultdict(lambda: len(vocab))\n",
    "UNK = vocab[\"<UNK>\"]\n",
    "PAD = vocab[\"<PAD>\"]\n",
    "\n",
    "# Build vocab from both question and answer\n",
    "for col in ['lemmatized_token_question', 'lemmatized_token_answer']:\n",
    "    for tokens in df[col]:\n",
    "        for token in tokens:\n",
    "            _ = vocab[token]\n",
    "\n",
    "word2idx = dict(vocab)\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "\n",
    "def vectorize(tokens, word2idx, max_len=10):\n",
    "    vec = [word2idx.get(token, word2idx[\"<UNK>\"]) for token in tokens]\n",
    "    vec = vec[:max_len] + [word2idx[\"<PAD>\"]] * (max_len - len(vec))\n",
    "    return vec\n",
    "\n",
    "df['question_vector'] = df['lemmatized_token_question'].apply(lambda x: vectorize(x, word2idx))\n",
    "df['answer_vector'] = df['lemmatized_token_answer'].apply(lambda x: vectorize(x, word2idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'answer', 'word_token_question', 'word_token_answer',\n",
       "       'lemmatized_token_question', 'lemmatized_token_answer',\n",
       "       'question_vector', 'answer_vector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FinQADataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.questions = df['question_vector'].tolist()\n",
    "        self.answers = df['answer_vector'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.questions[idx], dtype=torch.long),\n",
    "            torch.tensor(self.answers[idx], dtype=torch.long),\n",
    "        )\n",
    "\n",
    "train_dataset = FinQADataset(df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinQANet(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=256, hidden_dim=256):\n",
    "        super(FinQANet, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=word2idx[\"<PAD>\"])\n",
    "        \n",
    "        self.encoder = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # NEW: Project bidirectional encoder output to match decoder input size\n",
    "        self.encoder2decoder = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "        self.decoder = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input_ids, target_ids=None):\n",
    "        embedded = self.embedding(input_ids)  # [B, T, E]\n",
    "        enc_out, _ = self.encoder(embedded)   # [B, T, 2H]\n",
    "        \n",
    "        # Project encoder output to decoder input dimension\n",
    "        dec_input = self.encoder2decoder(enc_out)  # [B, T, H]\n",
    "        \n",
    "        if target_ids is not None:\n",
    "            # Optionally use target embeddings for teacher forcing\n",
    "            target_emb = self.embedding(target_ids)\n",
    "            dec_out, _ = self.decoder(target_emb)\n",
    "        else:\n",
    "            dec_out, _ = self.decoder(dec_input)  # fallback decode\n",
    "        \n",
    "        output = self.fc_out(dec_out)  # [B, T, V]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1544.8959\n",
      "Epoch 2/30, Loss: 333.4679\n",
      "Epoch 3/30, Loss: 136.9874\n",
      "Epoch 4/30, Loss: 39.6945\n",
      "Epoch 5/30, Loss: 4.8085\n",
      "Epoch 6/30, Loss: 1.5984\n",
      "Epoch 7/30, Loss: 0.9437\n",
      "Epoch 8/30, Loss: 0.5999\n",
      "Epoch 9/30, Loss: 0.3916\n",
      "Epoch 10/30, Loss: 0.2601\n",
      "Epoch 11/30, Loss: 0.1752\n",
      "Epoch 12/30, Loss: 0.1195\n",
      "Epoch 13/30, Loss: 0.0819\n",
      "Epoch 14/30, Loss: 0.0563\n",
      "Epoch 15/30, Loss: 0.0386\n",
      "Epoch 16/30, Loss: 0.0264\n",
      "Epoch 17/30, Loss: 0.0180\n",
      "Epoch 18/30, Loss: 0.0123\n",
      "Epoch 19/30, Loss: 0.0085\n",
      "Epoch 20/30, Loss: 0.0059\n",
      "Epoch 21/30, Loss: 0.0041\n",
      "Epoch 22/30, Loss: 0.0029\n",
      "Epoch 23/30, Loss: 0.0021\n",
      "Epoch 24/30, Loss: 0.0015\n",
      "Epoch 25/30, Loss: 0.0010\n",
      "Epoch 26/30, Loss: 0.0008\n",
      "Epoch 27/30, Loss: 0.0006\n",
      "Epoch 28/30, Loss: 0.0004\n",
      "Epoch 29/30, Loss: 0.0003\n",
      "Epoch 30/30, Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to device\n",
    "model = FinQANet(vocab_size=len(word2idx)).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"<PAD>\"])\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for input_ids, target_ids in train_loader:\n",
    "        # Move data to device\n",
    "        input_ids = input_ids.to(device)\n",
    "        target_ids = target_ids.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, target_ids)  # [batch, seq_len, vocab_size]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), target_ids.view(-1))\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Predicted Answer: mostly french40 falsify 10qs 20142015 20142015 20142015 consequence remain remain\n",
      "✅ Ground Truth: skimmer be most likely at gas station pump . if your debit card be compromise you be get money take out of your checking account which could cause a cascade of nsf fee . never use debit card at pump . clark howard call debit card piece of trash fake visamc that be because of all the point mention above but the most important fact be back in the 60 when congress be protect its constituent they make sure that the bank be responsible for fraud and maxe your liability at 50 . debit card be introduce much later when congress be interested in protect bank . so you have no protection on your debit card and if they find you negligent with your card they may not replace the steal fund . I get rid of my debit card and only have an atm card . so it can not be use in store which mean you have to know the pin and then you can only get 200 a day .\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_sample = torch.tensor(df['question_vector'].iloc[0]).unsqueeze(0).to(device)  # send to device\n",
    "    output = model(input_sample)\n",
    "\n",
    "    pred_ids = torch.argmax(output, dim=-1).squeeze(0)  # [seq_len]\n",
    "    predicted_tokens = [\n",
    "        idx2word[idx.item()]\n",
    "        for idx in pred_ids\n",
    "        if idx.item() not in {word2idx[\"<PAD>\"], word2idx[\"<UNK>\"]}\n",
    "    ]\n",
    "\n",
    "    print(\"🧠 Predicted Answer:\", \" \".join(predicted_tokens))\n",
    "    print(\"✅ Ground Truth:\", \" \".join(df['lemmatized_token_answer'].iloc[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
